\chapter{Workflows}\label{AppA}
\myappendices{Appendix ~\ref{AppA} ~\nameref{AppA}}
\section{Non-alcoholic fatty liver disease metagenomic workflow}

In this workflow, two annotation strategies were used. The first strategy is to create an annotated reference library to map sequenced reads to, and the second strategy is to annotate sequences assembled de novo from the reads, and map sequenced reads to these. The experiment could have been performed with only the second strategy and yielded a similar number of annotated reads. However, the second strategy is much more computationally intensive, so depending on the computational resources available, it may be worth using both strategies in conjunction, as described below.

\subsection{Filter OTUs}
In this experiment, the sequencing depth is expected to have the power to detect a 2 fold change up or down in bacteria that are 0.2\% abundant in a sample. The OTUs were filtered to remove any with an abundance lower than 0.2\% in all samples, and the OTU seed sequences were retrieved.

\subsection{Reference library annotation strategy}

\paragraph{Get reference library genomes}\mbox{}\\
The list of genomes used in the reference library was created using two sources: the Human Microbiome Project gut reference genomes (http://hmpdacc.org/HMRGD/healthy/), and the NCBI complete and draft bacterial genomes (http://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastSearch&BLAST_SPEC=MicrobialGenomes).

\paragraph{Human Microbiome Project}\mbox{}\\
The Human Microbiome Project gut reference genomes (http://hmpdacc.org/HMRGD/healthy/) were all added to the reference library genome list for the metagenomic study.

\paragraph{NCBI complete and draft bacterial genomes}\mbox{}\\
The draft and complete bacterial genomes can be queried here: \url{http://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastSearch&BLAST_SPEC=MicrobialGenomes}. During this process, we ran into a bug using the NCBI webtool and had to search once through the wgs database, and once with Complete Genomes to get both the draft and the complete genomes.

The BLAST output can be downloaded. In this case we were only interested in the genomes that matched with 98\% identity or greater. For these genomes we extracted the GI number, and performed web scraping in Python to visit \url{http://www.ncbi.nlm.nih.gov/nuccore/\<GI number\>} and programatically retrieve the taxon ID. The taxon ID is found in \url{ftp://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_genbank.txt} and the corresponding FTP link is used to download the genome. For each species found by this method, the genomes for 10 random strains are downloaded (or all of the strains if there are less than 10), to increase the coverage of the library.

\paragraph{Get reference library coding sequences}\mbox{}\\
Some of the genomes have a .gff file which includes the locations of the coding sequences already. For the rest, we used Glimmer \cite{delcher2007identifying} to predict open reading frames (ORFs).

\paragraph{Annotate reference library coding sequences}\mbox{}\\
Annotation was performed by querying the SEED database \cite{overbeek2005subsystems} using command line BLAST (\url{http://www.ncbi.nlm.nih.gov/books/NBK279690/}). This is the most computationally intensive part of the process and can take a number of days, depending on your computing platform. The specific SEED database we used was downloaded June 2013, and had the fig.pegs from the 2010 SEED database which are missing from the 2013 database manually added in. For each ORF, we retained the top 10 hits in the SEED database with an e-value cutoff of $10^{-3}$.

\subsection{De novo assembly annotation strategy}

\paragraph{Assembly}\mbox{}\\
The reads were assembled per sample using Trinity \cite{haas2013novo}.

\paragraph{Subtraction of reference library}\mbox{}\\
To prevent double counting, the assembled sequences were queried to the reference library. Any assembled sequences that matched a reference sequence with at least 90\% identity was removed.

\paragraph{Annotate de novo assembly}\mbox{}\\
Annotation was performed by querying the SEED database \cite{overbeek2005subsystems} using command line BLAST (\url{http://www.ncbi.nlm.nih.gov/books/NBK279690/}). This is the most computationally intensive part of the process and can take a number of days, depending on your computing platform. The specific SEED database we used was downloaded June 2013, and had the fig.pegs from the 2010 SEED database which are missing from the 2013 database manually added in. Because we did not isolate the coding sequences beforehnad, we devised a recursive BLAST strategy. For each round, we retained the top 10 hits in the SEED database per sequence with an e-value cutoff of $10^{-3}$. The portions of sequence greater than 500 nucleotides long that did not match the SEED hits were run through BLAST again.

\subsection{Map sequenced reads to reference library}
The reference library and the de novo assembly were amalgamated, and used to create a Bowtie2 index. The sequenced reads were mapped to this using Bowtie2 \cite{langmead2012fast}.

Custom scripts were used to convert the mapping output to a table of counts per annotation per sample, which can then be analyzed with differential expression tools such as ALDEx2 \cite{fernandes2014unifying}.

All of the custom scripts used to perform the above for the metagenomic non-alcoholic fatty liver disease experiment can be found on GitHub. Specifically, scripts for building the reference library can be accessed at \url{https://github.com/ruthgrace/make_functional_mapping_library}, scripts for annotating the reference library and mapping the sequenced reads can be accessed at \url{https://github.com/ruthgrace/mapping_library_annotated_counts}, and scripts for the de novo assembly annotation strategy can be found at \url{https://github.com/ruthgrace/exploring_nafld_assembly}.
